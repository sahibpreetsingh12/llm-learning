{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36aa5bbf",
   "metadata": {},
   "source": [
    "## Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e95428bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install llama-parse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc306ce2",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e145c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "201ea6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import shutup\n",
    "from llama_parse import LlamaParse\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "shutup.please()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8993613",
   "metadata": {},
   "source": [
    "go to llamaparse and make a account here and get a key -> [llamaparse](https://cloud.llamaindex.ai/login)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caf4f775",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# API access to llama-cloud\n",
    "os.environ[\"LLAMA_CLOUD_API_KEY\"] = \"llx-your-own-key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81371f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id de49e08f-2087-4168-87da-1a5f5eece1da\n"
     ]
    }
   ],
   "source": [
    "documents = LlamaParse(result_type=\"markdown\").load_data(\"sahib-cv_can-flowcv.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c6a58b",
   "metadata": {},
   "source": [
    "## Sample output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e493f7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Sahibpreet Singh\n",
      "\n",
      "Data Scientist\n",
      "\n",
      "ss9334931@gmail.com\n",
      "4 Larkberry Road, Ontario\n",
      "\n",
      "https://www.linkedin.com/in/sahibpreetsinghh/\n",
      "\n",
      "### PROFILE\n",
      "\n",
      "Accomplished Data Scientist specializing in NLP and Conversational AI. Top Kaggle mentor, ranked within the top 0.01%. Expert in cutting-edge models, delivering innovative solutions, and optimizing decision-making with data-driven insights. Strong analytical abilities, exceptional problem-solving skills, and a passion for impactful results.\n",
      "\n",
      "### PROFESSIONAL EXPERIENCE\n",
      "\n",
      "|Company|Date|Position|Location|\n",
      "|---|---|---|---|\n",
      "|Tatras Data|11/2022 â€“ 12/2023|Data Scientist|Chandigarh, India|\n",
      "|- Successfully delivered the product for Text-to-SQL problem using LLM with deployment using Streamlit and with Langchain as Framework.\n",
      "- Led the development of a centralized system aimed at streamlining the creation of contextual chatbots for diverse counties across the United States.\n",
      "- Transformed the chatbot development process by introducing a centralized serv...\n"
     ]
    }
   ],
   "source": [
    "print(documents[0].text[:1000] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08abff5d",
   "metadata": {},
   "source": [
    "## Saving parsed pdf to Txt File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4e834fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_from_pdf = json.loads(documents[0].to_json())['text']\n",
    "with open(\"resume.txt\", \"w\") as text_file:\n",
    "    text_file.write(text_from_pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12607ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data\n",
    "loader = TextLoader(\"resume.txt\")\n",
    "docs = loader.load()\n",
    "\n",
    "# Split text into chunks \n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98c3de78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the embedding model\n",
    "#using mixbread's embedding and in binary mode\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"mixedbread-ai/mxbai-embed-large-v1\",\n",
    "                                   encode_kwargs = {'precision': 'binary'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d533dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_key = 'gsk_your-own-key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72f72f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# FAISS the vector store \n",
    "vector = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "# Define a retriever interface\n",
    "retriever = vector.as_retriever()\n",
    "\n",
    "# Define LLM\n",
    "model = ChatGroq(temperature=0, groq_api_key=groq_key, model_name=\"llama3-8b-8192\")\n",
    "\n",
    "# Define prompt template\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "# Create a retrieval chain to answer questions\n",
    "document_chain = create_stuff_documents_chain(model, prompt)\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fdea614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name of the candidate is Sahibpreet Singh.\n",
      "CPU times: user 118 ms, sys: 352 ms, total: 470 ms\n",
      "Wall time: 2.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = retrieval_chain.invoke({\"input\": \"what is the name of the candidate\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e94218f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, Sahibpreet Singh has had the following jobs:\n",
      "\n",
      "1. Tatras Data (11/2022 - 12/2023) - Data Scientist\n",
      "2. ZS Associates (11/2021 - 11/2022) - Data Science Associate\n",
      "3. Tatras Data (07/2020 - 10/2021) - Junior Data Scientist\n",
      "\n",
      "So, in total, Sahibpreet Singh has had 3 jobs.\n",
      "CPU times: user 125 ms, sys: 428 ms, total: 553 ms\n",
      "Wall time: 2.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = retrieval_chain.invoke({\"input\": \"How many number of jobs in total he did?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1e0c35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the provided context, the first job of the candidate was as a Junior Data Scientist at Tatras Data from July 2020 to October 2021.\n",
      "CPU times: user 94.6 ms, sys: 290 ms, total: 384 ms\n",
      "Wall time: 1.64 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = retrieval_chain.invoke({\"input\": \"what was the first job of candidate?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a701f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb387e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
